# Phoenix collector target (use localhost if port-forwarding svc/phoenix)
PHOENIX_HOST=192.168.86.208
PHOENIX_PORT=6006
PHOENIX_COLLECTOR_ENDPOINT=http://192.168.86.208:6006
PHOENIX_PROJECT_NAME=local-llm-agent

# vLLM OpenAI-compatible endpoint
VLLM_API_BASE=http://192.168.86.202:8000/v1
VLLM_MODEL_NAME=Qwen/Qwen3-Coder-Next-FP8
OPENAI_API_KEY=not-needed

# Tavily web search
TAVILY_API_KEY=tvly-....(your key)
TAVILY_MAX_RESULTS=5
TAVILY_TOPIC=general

# Default prompt used by monitor_agent.py when --question is omitted
QUESTION=What are the key features and use cases of using Arize with large language models (LLMs)?
